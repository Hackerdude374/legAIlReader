================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-09-30T22:52:30.069Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
LegalAI-Assistant/backend/.env
LegalAI-Assistant/backend/app/api/document.py
LegalAI-Assistant/backend/app/api/support.py
LegalAI-Assistant/backend/app/main.py
LegalAI-Assistant/backend/app/services/document_analyzer.py
LegalAI-Assistant/backend/app/services/query_preprocessor.py
LegalAI-Assistant/backend/Dockerfile
LegalAI-Assistant/frontend/.env.local
LegalAI-Assistant/frontend/components/DocumentAnalyzer.js
LegalAI-Assistant/frontend/components/QueryPreprocessor.js
LegalAI-Assistant/frontend/Dockerfile
LegalAI-Assistant/frontend/package-lock.json
LegalAI-Assistant/frontend/pages/index.js
LegalAI-Assistant/infra/.github/workflows/ci.yml
LegalAI-Assistant/infra/docker-compose.yml
LegalAI-Assistant/ml/Dockerfile
LegalAI-Assistant/README.md
LegalAI-Assistant/repopack-output.txt
LICENSE

================================================================
Repository Files
================================================================

================
File: LegalAI-Assistant/backend/.env
================
POSTGRES_USER=user
POSTGRES_PASSWORD=your_secure_password
POSTGRES_DB=legalai

================
File: LegalAI-Assistant/backend/app/api/document.py
================
from fastapi import APIRouter, UploadFile, File
from ..services.document_analyzer import analyze_document

router = APIRouter()

@router.post("/analyze")
async def analyze_legal_document(file: UploadFile = File(...)):
    content = await file.read()
    result = analyze_document(content)
    return result

================
File: LegalAI-Assistant/backend/app/api/support.py
================
from fastapi import APIRouter
from pydantic import BaseModel
from ..services.query_preprocessor import preprocess_query

router = APIRouter()

class Query(BaseModel):
    text: str

@router.post("/preprocess")
async def preprocess_support_query(query: Query):
    result = preprocess_query(query.text)
    return result

================
File: LegalAI-Assistant/backend/app/main.py
================
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {"message": "Welcome to LegalAI Assistant API"}

# Import and include routers
from .api import document, support

app.include_router(document.router, prefix="/api/document", tags=["document"])
app.include_router(support.router, prefix="/api/support", tags=["support"])

================
File: LegalAI-Assistant/backend/app/services/document_analyzer.py
================
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_name = "nlpaueb/legal-bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

def analyze_document(content: bytes) -> dict:
    text = content.decode("utf-8")
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
    predicted_class = torch.argmax(probabilities, dim=-1).item()
    
    return {
        "class": predicted_class,
        "confidence": probabilities[0][predicted_class].item()
    }

================
File: LegalAI-Assistant/backend/app/services/query_preprocessor.py
================
from transformers import AutoTokenizer, AutoModel
import torch

model_name = "sentence-transformers/all-MiniLM-L6-v2"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

def preprocess_query(query: str) -> dict:
    inputs = tokenizer(query, return_tensors="pt", truncation=True, max_length=128)
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()
    
    return {
        "original_query": query,
        "embeddings": embeddings
    }

================
File: LegalAI-Assistant/backend/Dockerfile
================
FROM python:3.9

WORKDIR /app

COPY pyproject.toml poetry.lock* /app/

RUN pip install poetry && \
    poetry config virtualenvs.create false && \
    poetry install --no-dev

COPY . /app

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

================
File: LegalAI-Assistant/frontend/.env.local
================
NEXT_PUBLIC_API_URL=http://localhost:8000

================
File: LegalAI-Assistant/frontend/components/DocumentAnalyzer.js
================
import { useState } from 'react'

export default function DocumentAnalyzer() {
  const [file, setFile] = useState(null)
  const [result, setResult] = useState(null)

  const handleFileChange = (e) => {
    setFile(e.target.files[0])
  }

  const handleSubmit = async (e) => {
    e.preventDefault()
    if (!file) return

    const formData = new FormData()
    formData.append('file', file)

    try {
      const response = await fetch('http://localhost:8000/api/document/analyze', {
        method: 'POST',
        body: formData,
      })
      const data = await response.json()
      setResult(data)
    } catch (error) {
      console.error('Error analyzing document:', error)
    }
  }

  return (
    <div>
      <h2 className="text-2xl font-bold mb-4">Document Analysis</h2>
      <form onSubmit={handleSubmit}>
        <input type="file" onChange={handleFileChange} className="mb-4" />
        <button type="submit" className="bg-blue-500 text-white px-4 py-2">Analyze Document</button>
      </form>
      {result && (
        <div className="mt-8">
          <h3 className="text-xl font-bold mb-2">Analysis Result:</h3>
          <p>Class: {result.class}</p>
          <p>Confidence: {result.confidence.toFixed(4)}</p>
        </div>
      )}
    </div>
  )
}

================
File: LegalAI-Assistant/frontend/components/QueryPreprocessor.js
================
import { useState } from 'react'

export default function QueryPreprocessor() {
  const [query, setQuery] = useState('')
  const [result, setResult] = useState(null)

  const handleSubmit = async (e) => {
    e.preventDefault()
    if (!query) return

    try {
      const response = await fetch('http://localhost:8000/api/support/preprocess', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ text: query }),
      })
      const data = await response.json()
      setResult(data)
    } catch (error) {
      console.error('Error preprocessing query:', error)
    }
  }

  return (
    <div>
      <h2 className="text-2xl font-bold mb-4">Query Preprocessing</h2>
      <form onSubmit={handleSubmit}>
        <textarea
          value={query}
          onChange={(e) => setQuery(e.target.value)}
          className="w-full p-2 border rounded mb-4"
          rows="4"
          placeholder="Enter your query here"
        ></textarea>
        <button type="submit" className="bg-blue-500 text-white px-4 py-2">Preprocess Query</button>
      </form>
      {result && (
        <div className="mt-8">
          <h3 className="text-xl font-bold mb-2">Preprocessing Result:</h3>
          <p>Original Query: {result.original_query}</p>
          <p>Embeddings: {result.embeddings.slice(0, 5).map(e => e.toFixed(4)).join(', ')}...</p>
        </div>
      )}
    </div>
  )
}

================
File: LegalAI-Assistant/frontend/Dockerfile
================
FROM node:14

WORKDIR /app

COPY package.json package-lock.json ./
RUN npm install

COPY . .

RUN npm run build

CMD ["npm", "start"]

================
File: LegalAI-Assistant/frontend/package-lock.json
================
{
  "name": "frontend",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {}
}

================
File: LegalAI-Assistant/frontend/pages/index.js
================
import Head from 'next/head'
import { useState } from 'react'
import DocumentAnalyzer from '../components/DocumentAnalyzer'
import QueryPreprocessor from '../components/QueryPreprocessor'

export default function Home() {
  const [activeTab, setActiveTab] = useState('document')

  return (
    <div className="container mx-auto px-4">
      <Head>
        <title>LegalAI Assistant</title>
        <link rel="icon" href="/favicon.ico" />
      </Head>

      <main className="py-20">
        <h1 className="text-4xl font-bold mb-8 text-center">LegalAI Assistant</h1>
        
        <div className="flex justify-center mb-8">
          <button
            className={`px-4 py-2 mr-4 ${activeTab === 'document' ? 'bg-blue-500 text-white' : 'bg-gray-200'}`}
            onClick={() => setActiveTab('document')}
          >
            Document Analysis
          </button>
          <button
            className={`px-4 py-2 ${activeTab === 'query' ? 'bg-blue-500 text-white' : 'bg-gray-200'}`}
            onClick={() => setActiveTab('query')}
          >
            Query Preprocessing
          </button>
        </div>

        {activeTab === 'document' ? <DocumentAnalyzer /> : <QueryPreprocessor />}
      </main>
    </div>
  )
}

================
File: LegalAI-Assistant/infra/.github/workflows/ci.yml
================
name: Continuous Integration

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Install dependencies
      run: |
        pip install poetry
        poetry install
    - name: Run tests
      run: poetry run pytest

  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Install dependencies
      run: |
        pip install poetry
        poetry install
    - name: Run linter
      run: poetry run flake8

================
File: LegalAI-Assistant/infra/docker-compose.yml
================
version: '3.8'

services:
  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8000

  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/legalai
    depends_on:
      - db

  ml:
    build:
      context: ../ml
      dockerfile: Dockerfile
    environment:
      - MODEL_PATH=/app/models

  db:
    image: postgres:13
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=legalai
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:

================
File: LegalAI-Assistant/ml/Dockerfile
================
FROM python:3.9

WORKDIR /app

COPY pyproject.toml poetry.lock* /app/

RUN pip install poetry && \
    poetry config virtualenvs.create false && \
    poetry install --no-dev

COPY . /app

CMD ["python", "app/main.py"]

================
File: LegalAI-Assistant/README.md
================
# LegalAI Assistant

LegalAI Assistant is an AI-powered web application for legal document analysis and customer support query preprocessing. It demonstrates the integration of advanced NLP models with a modern web stack and MLOps practices.

## Features

- Legal document analysis using BERT-based models
- Customer support query preprocessing with sentence transformers
- User-friendly web interface built with Next.js
- Scalable backend API using FastAPI
- Containerized deployment with Docker and Docker Compose
- Continuous Integration and Deployment with GitHub Actions

## Tech Stack

- Frontend: Next.js, React, Tailwind CSS
- Backend: FastAPI (Python)
- AI/ML: PyTorch, Hugging Face Transformers, LangChain
- Database: PostgreSQL
- MLOps: Docker, GitHub Actions
- Other tools: Poetry (Python dependency management)

## Getting Started

1. Clone the repository
2. Navigate to the project root directory
3. Run docker-compose -f infra/docker-compose.yml up --build
4. Access the web application at http://localhost:3000

## Development

- Frontend: cd frontend && npm run dev
- Backend: cd backend && uvicorn app.main:app --reload
- ML: cd ml && python main.py

## Testing

Run pytest in the backend and ml directories.

## Deployment

Push to the main branch to trigger the CI/CD pipeline.

## License

This project is licensed under the MIT License.

================
File: LegalAI-Assistant/repopack-output.txt
================
================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-09-30T22:49:57.048Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
backend/app/api/document.py
backend/app/api/support.py
backend/app/main.py
backend/app/services/document_analyzer.py
backend/app/services/query_preprocessor.py
backend/Dockerfile
frontend/.env.local
frontend/components/DocumentAnalyzer.js
frontend/components/QueryPreprocessor.js
frontend/Dockerfile
frontend/package-lock.json
frontend/pages/index.js
infra/.github/workflows/ci.yml
infra/docker-compose.yml
ml/Dockerfile
README.md

================================================================
Repository Files
================================================================

================
File: backend/app/api/document.py
================
from fastapi import APIRouter, UploadFile, File
from ..services.document_analyzer import analyze_document

router = APIRouter()

@router.post("/analyze")
async def analyze_legal_document(file: UploadFile = File(...)):
    content = await file.read()
    result = analyze_document(content)
    return result

================
File: backend/app/api/support.py
================
from fastapi import APIRouter
from pydantic import BaseModel
from ..services.query_preprocessor import preprocess_query

router = APIRouter()

class Query(BaseModel):
    text: str

@router.post("/preprocess")
async def preprocess_support_query(query: Query):
    result = preprocess_query(query.text)
    return result

================
File: backend/app/main.py
================
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {"message": "Welcome to LegalAI Assistant API"}

# Import and include routers
from .api import document, support

app.include_router(document.router, prefix="/api/document", tags=["document"])
app.include_router(support.router, prefix="/api/support", tags=["support"])

================
File: backend/app/services/document_analyzer.py
================
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_name = "nlpaueb/legal-bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

def analyze_document(content: bytes) -> dict:
    text = content.decode("utf-8")
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
    predicted_class = torch.argmax(probabilities, dim=-1).item()
    
    return {
        "class": predicted_class,
        "confidence": probabilities[0][predicted_class].item()
    }

================
File: backend/app/services/query_preprocessor.py
================
from transformers import AutoTokenizer, AutoModel
import torch

model_name = "sentence-transformers/all-MiniLM-L6-v2"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

def preprocess_query(query: str) -> dict:
    inputs = tokenizer(query, return_tensors="pt", truncation=True, max_length=128)
    
    with torch.no_grad():
        outputs = model(**inputs)
    
    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().tolist()
    
    return {
        "original_query": query,
        "embeddings": embeddings
    }

================
File: backend/Dockerfile
================
FROM python:3.9

WORKDIR /app

COPY pyproject.toml poetry.lock* /app/

RUN pip install poetry && \
    poetry config virtualenvs.create false && \
    poetry install --no-dev

COPY . /app

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

================
File: frontend/.env.local
================
POSTGRES_USER=user
POSTGRES_PASSWORD=your_secure_password
POSTGRES_DB=legalai
NEXT_PUBLIC_API_URL=http://localhost:8000

================
File: frontend/components/DocumentAnalyzer.js
================
import { useState } from 'react'

export default function DocumentAnalyzer() {
  const [file, setFile] = useState(null)
  const [result, setResult] = useState(null)

  const handleFileChange = (e) => {
    setFile(e.target.files[0])
  }

  const handleSubmit = async (e) => {
    e.preventDefault()
    if (!file) return

    const formData = new FormData()
    formData.append('file', file)

    try {
      const response = await fetch('http://localhost:8000/api/document/analyze', {
        method: 'POST',
        body: formData,
      })
      const data = await response.json()
      setResult(data)
    } catch (error) {
      console.error('Error analyzing document:', error)
    }
  }

  return (
    <div>
      <h2 className="text-2xl font-bold mb-4">Document Analysis</h2>
      <form onSubmit={handleSubmit}>
        <input type="file" onChange={handleFileChange} className="mb-4" />
        <button type="submit" className="bg-blue-500 text-white px-4 py-2">Analyze Document</button>
      </form>
      {result && (
        <div className="mt-8">
          <h3 className="text-xl font-bold mb-2">Analysis Result:</h3>
          <p>Class: {result.class}</p>
          <p>Confidence: {result.confidence.toFixed(4)}</p>
        </div>
      )}
    </div>
  )
}

================
File: frontend/components/QueryPreprocessor.js
================
import { useState } from 'react'

export default function QueryPreprocessor() {
  const [query, setQuery] = useState('')
  const [result, setResult] = useState(null)

  const handleSubmit = async (e) => {
    e.preventDefault()
    if (!query) return

    try {
      const response = await fetch('http://localhost:8000/api/support/preprocess', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ text: query }),
      })
      const data = await response.json()
      setResult(data)
    } catch (error) {
      console.error('Error preprocessing query:', error)
    }
  }

  return (
    <div>
      <h2 className="text-2xl font-bold mb-4">Query Preprocessing</h2>
      <form onSubmit={handleSubmit}>
        <textarea
          value={query}
          onChange={(e) => setQuery(e.target.value)}
          className="w-full p-2 border rounded mb-4"
          rows="4"
          placeholder="Enter your query here"
        ></textarea>
        <button type="submit" className="bg-blue-500 text-white px-4 py-2">Preprocess Query</button>
      </form>
      {result && (
        <div className="mt-8">
          <h3 className="text-xl font-bold mb-2">Preprocessing Result:</h3>
          <p>Original Query: {result.original_query}</p>
          <p>Embeddings: {result.embeddings.slice(0, 5).map(e => e.toFixed(4)).join(', ')}...</p>
        </div>
      )}
    </div>
  )
}

================
File: frontend/Dockerfile
================
FROM node:14

WORKDIR /app

COPY package.json package-lock.json ./
RUN npm install

COPY . .

RUN npm run build

CMD ["npm", "start"]

================
File: frontend/package-lock.json
================
{
  "name": "frontend",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {}
}

================
File: frontend/pages/index.js
================
import Head from 'next/head'
import { useState } from 'react'
import DocumentAnalyzer from '../components/DocumentAnalyzer'
import QueryPreprocessor from '../components/QueryPreprocessor'

export default function Home() {
  const [activeTab, setActiveTab] = useState('document')

  return (
    <div className="container mx-auto px-4">
      <Head>
        <title>LegalAI Assistant</title>
        <link rel="icon" href="/favicon.ico" />
      </Head>

      <main className="py-20">
        <h1 className="text-4xl font-bold mb-8 text-center">LegalAI Assistant</h1>
        
        <div className="flex justify-center mb-8">
          <button
            className={`px-4 py-2 mr-4 ${activeTab === 'document' ? 'bg-blue-500 text-white' : 'bg-gray-200'}`}
            onClick={() => setActiveTab('document')}
          >
            Document Analysis
          </button>
          <button
            className={`px-4 py-2 ${activeTab === 'query' ? 'bg-blue-500 text-white' : 'bg-gray-200'}`}
            onClick={() => setActiveTab('query')}
          >
            Query Preprocessing
          </button>
        </div>

        {activeTab === 'document' ? <DocumentAnalyzer /> : <QueryPreprocessor />}
      </main>
    </div>
  )
}

================
File: infra/.github/workflows/ci.yml
================
name: Continuous Integration

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Install dependencies
      run: |
        pip install poetry
        poetry install
    - name: Run tests
      run: poetry run pytest

  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    - name: Install dependencies
      run: |
        pip install poetry
        poetry install
    - name: Run linter
      run: poetry run flake8

================
File: infra/docker-compose.yml
================
version: '3.8'

services:
  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8000

  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/legalai
    depends_on:
      - db

  ml:
    build:
      context: ../ml
      dockerfile: Dockerfile
    environment:
      - MODEL_PATH=/app/models

  db:
    image: postgres:13
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=legalai
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:

================
File: ml/Dockerfile
================
FROM python:3.9

WORKDIR /app

COPY pyproject.toml poetry.lock* /app/

RUN pip install poetry && \
    poetry config virtualenvs.create false && \
    poetry install --no-dev

COPY . /app

CMD ["python", "app/main.py"]

================
File: README.md
================
# LegalAI Assistant

LegalAI Assistant is an AI-powered web application for legal document analysis and customer support query preprocessing. It demonstrates the integration of advanced NLP models with a modern web stack and MLOps practices.

## Features

- Legal document analysis using BERT-based models
- Customer support query preprocessing with sentence transformers
- User-friendly web interface built with Next.js
- Scalable backend API using FastAPI
- Containerized deployment with Docker and Docker Compose
- Continuous Integration and Deployment with GitHub Actions

## Tech Stack

- Frontend: Next.js, React, Tailwind CSS
- Backend: FastAPI (Python)
- AI/ML: PyTorch, Hugging Face Transformers, LangChain
- Database: PostgreSQL
- MLOps: Docker, GitHub Actions
- Other tools: Poetry (Python dependency management)

## Getting Started

1. Clone the repository
2. Navigate to the project root directory
3. Run docker-compose -f infra/docker-compose.yml up --build
4. Access the web application at http://localhost:3000

## Development

- Frontend: cd frontend && npm run dev
- Backend: cd backend && uvicorn app.main:app --reload
- ML: cd ml && python main.py

## Testing

Run pytest in the backend and ml directories.

## Deployment

Push to the main branch to trigger the CI/CD pipeline.

## License

This project is licensed under the MIT License.

================
File: LICENSE
================
MIT License

Copyright (c) 2024 Robert 

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
